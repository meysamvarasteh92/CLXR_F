{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b69078",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160299a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import optuna\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import ipynb\n",
    "import wandb\n",
    "import importlib\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d9f2b-37ce-4c7c-9d2e-8e0a7d8d1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"MLP\" ## Can be MLP, VAE\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir.parent, DP_DIR)\n",
    "checkpoints_path = Path(export_dir, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33658aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\"\n",
    "}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155\n",
    "}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "recommender_path_dict = {\n",
    "    #(\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0003_64.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    \n",
    "    #(\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_128.pt\"),\n",
    "\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "\n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_0.0002_32_12.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\")\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    #(\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"VAE\"): [256,64],\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512\n",
    "\n",
    "}\n",
    "\n",
    "Populairty_filtering=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a6b87",
   "metadata": {},
   "source": [
    "## Data imports and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "train_data['user_id'] = train_data.index\n",
    "test_data['user_id'] = test_data.index\n",
    "static_test_data = pd.read_csv(Path(files_path,f'static_test_data_{data_name}.csv'), index_col=0)\n",
    "\n",
    "with open(Path(files_path,f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f)\n",
    "\n",
    "######## Removing most popular itemd from training and testing datasets for Filter_pop baseline\n",
    "if (Populairty_filtering ==True): \n",
    "    sorted_dict = dict(sorted(pop_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "    Top_pop_items=list(sorted_dict.keys())[0:500]\n",
    "    for i in Top_pop_items:\n",
    "        train_data.iloc[:,i]=0\n",
    "        test_data.iloc[:,i]=0\n",
    "        static_test_data.iloc[:,i]=0\n",
    "\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()\n",
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abdd7e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_array = np.zeros(len(pop_dict))\n",
    "for key, value in pop_dict.items():\n",
    "    pop_array[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "          'pop_array':pop_array,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'static_test_data':static_test_data,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2db85e",
   "metadata": {},
   "source": [
    "# Recommenders Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cf0c0-8f2d-47b0-9fce-82f0f7d11f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eabb32-7711-4df3-92b1-f937e2fff5c3",
   "metadata": {},
   "source": [
    " # VAE Config (for VAE model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c494e3-e4b0-40b2-979d-928573817dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_config = { \"enc_dims\": [256, 64], \"dropout\": 0.5, \"anneal_cap\": 0.2, \"total_anneal_steps\": 200000 }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc9faf-f6e7-438a-8a01-a7da7ea8c182",
   "metadata": {},
   "source": [
    "# Loading recommender systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276bcee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recommender():\n",
    "    if recommender_name=='MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name=='VAE':\n",
    "        recommender = VAE(VAE_config, **kw_dict)\n",
    "    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path), map_location=torch.device('cpu'))\n",
    "    recommender.load_state_dict(recommender_checkpoint)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad= False\n",
    "    return recommender\n",
    "    \n",
    "recommender = load_recommender()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc79dc",
   "metadata": {},
   "source": [
    "# Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommended_item(user_tensor, recommender, **kw):\n",
    "    all_items_tensor = kw['all_items_tensor']\n",
    "    num_items = kw['num_items']\n",
    "    user_res = recommender_run(user_tensor, recommender, all_items_tensor, None, 'vector', **kw)[:num_items]\n",
    "    user_tensor = user_tensor[:num_items]\n",
    "    user_catalog = torch.ones_like(user_tensor)-user_tensor\n",
    "    user_recommenations = torch.mul(user_res, user_catalog)\n",
    "    # Get the indices of the items sorted by their recommendation score in descending order\n",
    "    sorted_recommendations = torch.argsort(user_recommenations, descending=True)\n",
    "    return(sorted_recommendations[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba496f",
   "metadata": {},
   "source": [
    "## Load / create top recommended items dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load / create top recommended items dict\n",
    "\n",
    "create_dicts = True\n",
    "if create_dicts:\n",
    "\n",
    "    ## target and comparative items for training \n",
    "    targ_train, cmp_train = {}, {}\n",
    "    ## target and comparative items for testing \n",
    "    targ_test, cmp_test = {}, {}\n",
    "   \n",
    "    for i in range(train_array.shape[0]):\n",
    "        user_index = train_array[i][-1]\n",
    "        user_tensor = torch.Tensor(train_array[i][:-1]).to(device)\n",
    "        recomm_list=get_user_recommended_item(user_tensor, recommender, **kw_dict)\n",
    "        \n",
    "        ## Target item as the first item rank\n",
    "        targ_train[user_index] = int(recomm_list[0])\n",
    "        \n",
    "        ## Sampling for the comparative item below the target item\n",
    "        cmp_train[user_index]= np.array(recomm_list[1:9].cpu())\n",
    "\n",
    "    for i in range(test_array.shape[0]):\n",
    "        user_index = test_array[i][-1]\n",
    "        user_tensor = torch.Tensor(test_array[i][:-1]).to(device)\n",
    "        recomm_list=get_user_recommended_item(user_tensor, recommender, **kw_dict)\n",
    "        \n",
    "        ## Target item as the first item rank\n",
    "        targ_test[user_index] = int(recomm_list[0])\n",
    "        \n",
    "        ## Sampling for the comparative item below the target item\n",
    "        cmp_test[user_index] = np.array(recomm_list[1:9].cpu())\n",
    "\n",
    "    with open(Path(files_path,f'targ_train_{data_name}_{recommender_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(targ_train, f)\n",
    "    with open(Path(files_path,f'cmp_train_{data_name}_{recommender_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(cmp_train, f)\n",
    "    with open(Path(files_path,f'targ_test_{data_name}_{recommender_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(targ_test, f)\n",
    "    with open(Path(files_path,f'cmp_test_{data_name}_{recommender_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(cmp_test, f)\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    with open(Path(files_path,f'targ_train_{data_name}_{recommender_name}.pkl'), 'rb') as f:\n",
    "        targ_train = pickle.load(f)\n",
    "    with open(Path(files_path,f'cmp_train_{data_name}_{recommender_name}.pkl'), 'rb') as f:\n",
    "        cmp_train = pickle.load(f)\n",
    "    with open(Path(files_path,f'targ_test_{data_name}_{recommender_name}.pkl'), 'rb') as f:\n",
    "        targ_test = pickle.load(f)\n",
    "    with open(Path(files_path,f'cmp_test_{data_name}_{recommender_name}.pkl'), 'rb') as f:\n",
    "        cmp_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f47d6",
   "metadata": {},
   "source": [
    "# Explinaer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c44742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explainer(nn.Module):\n",
    "    def __init__(self, user_size, item_size, hidden_size):\n",
    "        super(Explainer, self).__init__()\n",
    "        \n",
    "        self.users_fc = nn.Linear(in_features = user_size, out_features=hidden_size).to(device)\n",
    "        self.items_fc = nn.Linear(in_features = item_size, out_features=hidden_size).to(device)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features = hidden_size*2, out_features=hidden_size).to(device),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features = hidden_size, out_features=user_size).to(device),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, user_tensor, item_tensor):\n",
    "        user_output = self.users_fc(user_tensor.float())\n",
    "        item_output = self.items_fc(item_tensor.float())\n",
    "        combined_output = torch.cat((user_output, item_output), dim=-1)\n",
    "        expl_scores = self.bottleneck(combined_output).to(device)\n",
    "        \n",
    "        return expl_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd6ce4a-741e-485a-a0b8-455f87477c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_CLXR_mask(user_tensor, i1_tensor,i2_tensor,explainer):\n",
    "    \n",
    "    ## Mask for target item\n",
    "    m1 = explainer(user_tensor, i1_tensor)\n",
    "    ## Mask for comparative item\n",
    "    m2 = explainer(user_tensor, i2_tensor)\n",
    "    ## Contrastive mask (m1*(1-m2))\n",
    "    m3 =(1-m2)*m1\n",
    "\n",
    "    ## Multiplying users profile by the contrastive mask\n",
    "    x_m3 = user_tensor* m3 \n",
    "\n",
    "    \n",
    "    m3_dict = {i: x_m3[i].item() for i in range(len(x_m3))}   \n",
    "\n",
    "    return m3_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3557f3",
   "metadata": {},
   "source": [
    "# CLXR Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a626ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLXR_loss(nn.Module):\n",
    "\n",
    "    def __init__(self, lambda_pos, lambda_neg,lambda_cmp_m1, lambda_cmp_m3, lambda_cmp_neg, alpha):\n",
    "        super(CLXR_loss, self).__init__()\n",
    "        \n",
    "        self.lambda_pos = lambda_pos\n",
    "        self.lambda_neg = lambda_neg\n",
    "\n",
    "        self.lambda_cmp_m1= lambda_cmp_m1\n",
    "        self.lambda_cmp_m3= lambda_cmp_m3\n",
    "        self.lambda_cmp_neg=lambda_cmp_neg\n",
    "        \n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, user_tensors, i1_tensors, i2_tensors, i1_id, i2_id, m1, m2, m3):\n",
    "\n",
    "        \n",
    "        neg_m1 = torch.sub(torch.ones_like(m1), m1)\n",
    "        \n",
    "        neg_m3 = torch.sub(torch.ones_like(m3), m3)\n",
    "        \n",
    "        xm1_pos = user_tensors * m1\n",
    "        \n",
    "        xm2_pos = user_tensors * m2\n",
    "        \n",
    "        xm3_pos= user_tensors * (m3)\n",
    "\n",
    "        xm1_neg = user_tensors * neg_m1\n",
    "        \n",
    "        xm3_neg= user_tensors * neg_m3\n",
    "\n",
    "        if output_type=='single':\n",
    "            \n",
    "            ## Recommeder output for the target item by applying m1 mask (m1 is the mask for the target item)\n",
    "            y1_m1_pos = torch.diag(recommender_run(xm1_pos, recommender, i1_tensors, item_id=i1_id, wanted_output = 'single', **kw_dict))\n",
    "\n",
    "             ## Negative mask version for the target item\n",
    "            y1_m1_neg = torch.diag(recommender_run(xm1_neg, recommender, i1_tensors, item_id=i1_id, wanted_output = 'single', **kw_dict))\n",
    "            \n",
    "            ## Recommeder output for the comparative item by applying m2 mask (m2 is the mask for the comparative item)\n",
    "            y2_m2_pos = torch.diag(recommender_run(xm2_pos, recommender, i2_tensors, item_id=i2_id, wanted_output = 'single', **kw_dict))\n",
    "\n",
    "            ## Recommeder outputs for the target and comparative items by masking m3=m1*(1-m2) (comparatvie mask). target and comparative outputs for the comparative mask\n",
    "            y1_m3_pos= torch.diag(recommender_run(xm3_pos, recommender, i1_tensors, item_id=i1_id, wanted_output = 'single', **kw_dict))\n",
    "            y2_m3_pos= torch.diag(recommender_run(xm3_pos, recommender, i2_tensors, item_id=i2_id, wanted_output = 'single', **kw_dict))\n",
    "\n",
    "           \n",
    "            ## Negative comparative mask for the comparative item\n",
    "            y2_m3_neg= torch.diag(recommender_run(xm3_neg, recommender, i2_tensors, item_id=i2_id, wanted_output = 'single', **kw_dict))\n",
    "\n",
    "        else:\n",
    "            \n",
    "            ### target item output\n",
    "            y1_m1_pos = recommender_run(xm1_pos, recommender, i1_tensors, item_id=i1_id, wanted_output = 'vector', **kw_dict)\n",
    "            y1_m1_neg = recommender_run(xm1_neg, recommender, i1_tensors, item_id=i1_id, wanted_output = 'vector', **kw_dict)\n",
    "\n",
    "            ### comparative item\n",
    "            y2_m2_pos= recommender_run(xm2_pos, recommender, i2_tensors, item_id=i2_id, wanted_output = 'vector', **kw_dict)\n",
    "\n",
    "            \n",
    "            rows1=torch.arange(len(i1_id))\n",
    "            rows2=torch.arange(len(i2_id))\n",
    "\n",
    "            y1_m1_pos = y1_m1_pos[rows1, i1_id] \n",
    "            y1_m1_neg = y1_m1_neg[rows1, i1_id] \n",
    "            y2_m2_pos = y2_m2_pos[rows2, i2_id] \n",
    "\n",
    "\n",
    "            y1_m3_pos= recommender_run(xm3_pos, recommender, i1_tensors, item_id=i1_id, wanted_output = 'vector', **kw_dict)\n",
    "            y2_m3_pos= recommender_run(xm3_pos, recommender, i2_tensors, item_id=i2_id, wanted_output = 'vector', **kw_dict)\n",
    "            \n",
    "            y1_m3_pos=y1_m3_pos[rows1, i1_id] \n",
    "            y2_m3_pos=y2_m3_pos[rows2, i2_id] \n",
    "\n",
    "            \n",
    "            y2_m3_neg=recommender_run(xm3_neg, recommender, i2_tensors, item_id=i2_id, wanted_output = 'vector', **kw_dict)\n",
    "            y2_m3_neg=y2_m3_neg[rows2, i2_id] \n",
    "            \n",
    "          \n",
    "\n",
    "        ## First loss term  ( maximizing rating score of the target item  for the positive and negative masks (same as LXR)   )\n",
    "        pos_loss = - self.lambda_pos *torch.mean(torch.log(y1_m1_pos))\n",
    "        neg_loss = self.lambda_neg * torch.mean(torch.log(y1_m1_neg))\n",
    "\n",
    "        ## Second Loss term, comparative term ( minimizing the distance between the target and contarstive items  rating scores by masking m1 )\n",
    "        cmp_loss_m1 = - self.lambda_cmp_m1 * torch.mean(torch.log(1+torch.exp(-(y1_m1_pos-y2_m2_pos))))\n",
    "        cmp_loss_m3 = - self.lambda_cmp_m3 * torch.mean(torch.log(1+torch.exp(y1_m3_pos-y2_m3_pos)))\n",
    "        cmp_loss_neg = self.lambda_cmp_neg * torch.mean(torch.log(torch.exp(y2_m3_neg))) \n",
    "\n",
    "\n",
    "        ## Third term ( sparsity terms )\n",
    "        l = self.alpha * xm1_pos[user_tensors>0].mean() + self.alpha * xm3_pos[user_tensors>0].mean()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        ### combined loss (summing up all the terms\n",
    "        combined_loss = pos_loss + neg_loss  + cmp_loss_m1+ cmp_loss_m3 +  cmp_loss_neg  + l        \n",
    "\n",
    "        return combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d703ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i1: Id of target item\n",
    "# i1_tensors: convert target id to an one-hot tensor\n",
    "# i2: Id of comparative item  \n",
    "#i1_tensors: convert comparative id to an one-hot tensor\n",
    "\n",
    "def calculate_pos_neg_k(user_tensor, i1, i2, i1_tensors, i2_tensors, num_of_bins, explainer, k):\n",
    "    \n",
    "    user_hist_size = int(torch.sum(user_tensor))\n",
    "    bins = [0] + [len(x) for x in np.array_split(np.arange(user_hist_size), num_of_bins, axis=0)]\n",
    "\n",
    "\n",
    "    # Helper function to mask items\n",
    "    def mask_items(user_tensor, sorted_m3, total_items, device):\n",
    "        mask = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        indices = [item[0] for item in sorted_m3[:total_items]]\n",
    "        mask[indices] = 1\n",
    "        return user_tensor - mask\n",
    "\n",
    "    # Process each item set (first, second, comparative)\n",
    "    def process_sim_items(m3, i1, i2, bins, user_tensor, user_hist_size, recommender, **kw_dict):\n",
    "      \n",
    "        sorted_m3 = list(sorted(m3.items(), key=lambda item: item[1], reverse=True))[:user_hist_size]\n",
    "\n",
    "        total_items = 0\n",
    "        for index, bin_size in enumerate(bins):\n",
    "            total_items += bin_size\n",
    "\n",
    "            ## Perturbations\n",
    "            p = mask_items(user_tensor, sorted_m3, total_items, device)\n",
    "\n",
    "\n",
    "            ## Rank of target item and comparative item by masking m3\n",
    "            i1_rank = get_index_in_the_list(p, user_tensor, i1, recommender, **kw_dict) + 1\n",
    "            i2_rank = get_index_in_the_list(p, user_tensor, i2, recommender, **kw_dict) + 1\n",
    "            \n",
    "            if (i1_rank > i2_rank):\n",
    "                \n",
    "                return total_items, index   ## returning the perturbation that lead to reverse target and comparative items and also index of bin\n",
    "            \n",
    "          \n",
    "    \n",
    "        return None, None\n",
    "\n",
    "    # Find CLXR masks (m3)\n",
    "    m3 = find_CLXR_mask(\n",
    "        user_tensor, i1_tensors, i2_tensors, explainer)\n",
    "    \n",
    "    #### total items to be removed from the users profile to have reversion of ranking target item and contrastive item\n",
    "    total_items, bin_index=process_sim_items(m3, i1, i2, bins, user_tensor, user_hist_size, recommender, **kw_dict)\n",
    "    \n",
    "  \n",
    "    return total_items, bin_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1befb216",
   "metadata": {},
   "source": [
    "# CLXR training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "num_of_rand_users = 700 # number of users for evaluations\n",
    "random_rows = np.random.choice(test_array.shape[0], num_of_rand_users, replace=False)\n",
    "random_sampled_array = test_array[random_rows]\n",
    "\n",
    "def clxr_training(trial):\n",
    "\n",
    "    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.01)\n",
    "\n",
    "    ## Hyperparameters for the first term of loss\n",
    "    lambda_neg = trial.suggest_float('lambda_neg', 0,50)\n",
    "\n",
    "    lambda_pos = trial.suggest_float('lambda_pos', 0,50)\n",
    "\n",
    "    ## Hyperparameters for the second term of loss\n",
    "    lambda_cmp_m1 = trial.suggest_float('lambda_cmp_m1', 0,50)   # For the m1 mask of contrastive term (2nd term)\n",
    "    lambda_cmp_m3 = trial.suggest_float('lambda_cmp_m3', 0,50)   # For the m3 mask of contrastive term (2nd term)\n",
    "    lambda_cmp_neg =  trial.suggest_float('lambda_cmp_neg', 0,50)   # For the m3 (negative part) mask of contrastive term (2nd term)\n",
    "\n",
    "    \n",
    "    # Hyperparameter for the third term of loss (sparsity term)\n",
    "    alpha = trial.suggest_categorical('alpha', [1]) # set alpha to be 1, change other hyperparameters\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32,64,128,256])\n",
    "\n",
    "    explainer_hidden_size = trial.suggest_categorical('explainer_hidden_size', [32,64,128])\n",
    "\n",
    "    epochs = 50\n",
    "    \n",
    "    wandb.init(\n",
    "        project=f\"{data_name}_{recommender_name}_CLXR_training\",\n",
    "        name=f\"trial_{trial.number}\",\n",
    "        config={\n",
    "        'learning_rate' : learning_rate,\n",
    "        'alpha' : alpha,\n",
    "        'lambda_neg' : lambda_neg,\n",
    "        'lambda_pos' : lambda_pos,\n",
    "        'lambda_cmp_m1' : lambda_cmp_m1,\n",
    "        'lambda_cmp_m3' : lambda_cmp_m3,\n",
    "        'lambda_cmp_neg' : lambda_cmp_neg,\n",
    "        'batch_size' : batch_size,\n",
    "        'explainer_hidden_size' : explainer_hidden_size,\n",
    "        'architecture' : 'CLXR_combined',\n",
    "        'activation_function' : 'Tanh',\n",
    "        'loss_type' : 'logloss',\n",
    "        'optimize_for' : 'pos_at_20',\n",
    "        'epochs':epochs\n",
    "        })\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(train_array, batch_size=batch_size, shuffle=True)\n",
    "    num_batches = int(np.ceil(train_array.shape[0] / batch_size))\n",
    "    num_of_bins = 10\n",
    "\n",
    "    ## A list for storing all bin index in all epochs. To select the best value among epochs\n",
    "    tot_bin_indx=[]\n",
    "    \n",
    "    ## A list for storing all flipping values (number of users that reversion occurs) in all epochs. To select the best value among epochs\n",
    "    flip_total=[]\n",
    "    \n",
    "    ## A list for storing perturbations in all epochs. To select the best value among epochs\n",
    "    total_items= []\n",
    "    \n",
    "    train_losses = []\n",
    "\n",
    "    recommender.eval()\n",
    "\n",
    "    num_features = num_items_dict[data_name]\n",
    "\n",
    "    explainer = Explainer(num_features, num_items, explainer_hidden_size).to(device) \n",
    "\n",
    "    optimizer_comb = torch.optim.Adam(explainer.parameters(), learning_rate)\n",
    "    loss_func = CLXR_loss(lambda_pos, lambda_neg,lambda_cmp_m1, lambda_cmp_m3, lambda_cmp_neg, alpha)\n",
    "\n",
    "    print('======================== new run ========================')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if epoch%15 == 0 and epoch>0: # decrease learning rate every 15 epochs\n",
    "            learning_rate*= 0.1\n",
    "            optimizer_comb.lr = learning_rate\n",
    "\n",
    "        \n",
    "        train_loss=0\n",
    "        explainer.train()\n",
    "        \n",
    "        for batch_index, samples in enumerate(loader):\n",
    "            # prepare data for explainer:\n",
    "            user_tensors = torch.tensor(samples[:, :-1], dtype=torch.float, device=device)\n",
    "\n",
    "            user_ids = samples[:,-1]\n",
    "            ### target items batch for training explainer (i1 is the target item id)\n",
    "            i1 = np.array([targ_train[int(x)] for x in user_ids])  \n",
    "\n",
    "            ### contrastive items batch for training explainer (i2 is the comparative item id)\n",
    "            i2 = np.array([np.random.choice(cmp_train[int(x)]) for x in user_ids])\n",
    "\n",
    "        \n",
    "            i1_vectors = items_array[i1]\n",
    "            i2_vectors = items_array[i2]\n",
    "            \n",
    "            ### converting to a tensor\n",
    "            i1_tensors = torch.Tensor(i1_vectors).to(device)\n",
    "            i2_tensors = torch.Tensor(i2_vectors).to(device)\n",
    "            n = user_tensors.shape[0]\n",
    "\n",
    "            # zero grad:\n",
    "            optimizer_comb.zero_grad()\n",
    "            # forward:\n",
    "            #### scores for the target item\n",
    "            m1 = explainer(user_tensors, i1_tensors)\n",
    "            \n",
    "            #### scores for the contrastive item\n",
    "            m2= explainer(user_tensors, i2_tensors)\n",
    "            \n",
    "            #### comparative scores (m3)\n",
    "            m3 =(1-m2)*m1\n",
    "\n",
    "            # calculate loss\n",
    "            comb_loss = loss_func(user_tensors, i1_tensors , i2_tensors, i1, i2, m1, m2, m3)\n",
    "    \n",
    "            train_loss += comb_loss*n\n",
    "\n",
    "            # back propagation\n",
    "            comb_loss.backward()\n",
    "            optimizer_comb.step()\n",
    "\n",
    "        \n",
    "\n",
    "        torch.save(explainer.state_dict(), Path(checkpoints_path, f'CLXR_{data_name}_{recommender_name}_{trial.number}_{epoch}_{explainer_hidden_size}_{lambda_pos}_{lambda_neg}.pt'))\n",
    "        \n",
    "        explainer.eval()\n",
    "        \n",
    "        ## Storing bin indexes in each epoch\n",
    "        bin_indx=[]\n",
    "        \n",
    "        ## storing perturbations in each epoch\n",
    "        tot_items=[]\n",
    "        \n",
    "        for j in range(random_sampled_array.shape[0]):\n",
    "\n",
    "            user_id = random_sampled_array[j][-1]\n",
    "            user_tensor = torch.Tensor(random_sampled_array[j][:-1]).to(device)\n",
    "            \n",
    "            ## Target item for testing dataset\n",
    "            i1 = targ_test[user_id]\n",
    "            \n",
    "            ## Comparative item for testing dataset\n",
    "            i2=np.random.choice(cmp_test[user_id])\n",
    "\n",
    "            i1_vector = items_array[i1]\n",
    "            i2_vector = items_array[i2]\n",
    "\n",
    "            i1_tensor = torch.Tensor(i1_vector).to(device)\n",
    "            i2_tensor = torch.Tensor(i2_vector).to(device)\n",
    "            \n",
    "            p, ind= calculate_pos_neg_k(user_tensor, i1, i2, i1_tensor, i2_tensor, num_of_bins, explainer, k=10)\n",
    "\n",
    "            if p is not None:\n",
    "                \n",
    "                bin_indx.append(ind)\n",
    "                tot_items.append(p)\n",
    "            \n",
    "              \n",
    "\n",
    "        flip_total.append(len(bin_indx))  \n",
    "    \n",
    "        ## average of total items for each epoch\n",
    "        items_avg=np.mean(tot_items)\n",
    "        ## creating a list for storing values of \"total_items_avg\" in each epoch\n",
    "        total_items.append(items_avg)\n",
    "\n",
    "        \n",
    "        tot_bin_indx.append(np.mean(bin_indx))\n",
    "        \n",
    "    \n",
    "        print(f'Finished epoch {epoch} with  MPRR(raw) {np.mean(tot_items)}, MPRR(%) {np.mean(bin_indx)*10},'\n",
    "        f'and Coverage (%) {len(bin_indx)*100/num_of_rand_users}')\n",
    "\n",
    "    \n",
    "        \n",
    "    print(f'Stop at trial with learning rate {learning_rate}, batch size={batch_size},' \n",
    "    f'explainer hidden size={explainer_hidden_size}, lambda_pos = {lambda_pos}, '\n",
    "    f'lambda_neg = {lambda_neg}, alpha_parameter = {alpha}, lambda_cmp_m1 = {lambda_cmp_m1}, '\n",
    "    f'lambda_cmp_m3 = {lambda_cmp_m3}, lambda_cmp_neg ={lambda_cmp_neg} .' \n",
    "    f'Best results at epoch {np.argmin(total_items)} with MPRR (raw) {np.min(total_items)},'\n",
    "    f'MPRR (%)  {tot_bin_indx[np.argmin(total_items)]*10}'\n",
    "    f'and Coverage with value {flip_total[np.argmin(total_items)]*100/num_of_rand_users}')    \n",
    "    \n",
    "    \n",
    "    return np.max(flip_total)*100/ num_of_rand_users # return the best total items value in this trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86931e41",
   "metadata": {},
   "source": [
    "### Save logs in text file, optimize using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118fc6ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "\n",
    "logger.setLevel(logging.INFO)  # Setup the root logger.\n",
    "logger.addHandler(logging.FileHandler(f\"{data_name}_{recommender_name}_explainer_training.log\", mode=\"w\"))\n",
    "\n",
    "optuna.logging.enable_propagation()  # Propagate logs to the root logger.\n",
    "optuna.logging.disable_default_handler()  # Stop showing logs in sys.stderr.\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "logger.info(\"Start optimization.\")\n",
    "study.optimize(clxr_training, n_trials=50)   ## For finding the best hyperparameters.\n",
    "\n",
    "with open(f\"{data_name}_{recommender_name}_explainer_training.log\") as f:\n",
    "    assert f.readline().startswith(\"A new study created\")\n",
    "    assert f.readline() == \"Start optimization.\\n\"\n",
    "    \n",
    "    \n",
    "# Print best hyperparameters and corresponding metric value\n",
    "print(\"Best hyperparameters: {}\".format(study.best_params))\n",
    "print(\"Best metric value: {}\".format(study.best_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
